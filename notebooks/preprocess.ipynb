{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sandernoels/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from typing import Optional\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import DatasetDict, Dataset, load_from_disk\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.data_processing.translations_fingpt import (ner_cls_translations,\n",
    "                                                     ner_translations,\n",
    "                                                     finred_re_translations,\n",
    "                                                     finred_general,\n",
    "                                                     finred_translations,\n",
    "                                                     finred_cls_translations,\n",
    "                                                     headline_translations, \n",
    "                                                     sentiment_translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence: str, translations: dict) -> str:\n",
    "    for eng, dutch in translations.items():\n",
    "        if eng in sentence:\n",
    "            sentence = sentence.replace(eng, dutch)\n",
    "    return sentence\n",
    "\n",
    "def replace_dataset_col_with_transaltion(dataset,translations):\n",
    "    for dataset_keys in dataset.keys():\n",
    "        pd_df = dataset[dataset_keys].to_pandas()\n",
    "\n",
    "        text_translations = list(pd_df['instruction'].apply(lambda x : translate_sentence(x,translations)))\n",
    "       \n",
    "        new_dataset = dataset[dataset_keys].remove_columns(\"instruction\")\n",
    "        dataset_with_new_translation = new_dataset.add_column(\n",
    "            \"instruction\", text_translations\n",
    "        )\n",
    "        dataset[dataset_keys] = dataset_with_new_translation\n",
    "    return dataset\n",
    "\n",
    "def save_new_dataset(target_location: str, train: pd.DataFrame, test: Optional[pd.DataFrame] = None):\n",
    "    ds = DatasetDict({\n",
    "        'train': Dataset.from_pandas(train, preserve_index=False)\n",
    "    })\n",
    "\n",
    "    if test is not None:\n",
    "        ds['test'] = Dataset.from_pandas(test, preserve_index=False)\n",
    "\n",
    "    ds.save_to_disk(target_location)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER-CLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk('../data/FinGPT/fingpt-ner-cls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = replace_dataset_col_with_transaltion(dataset, ner_cls_translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 13549/13549 [00:00<00:00, 1053142.55 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 3502/3502 [00:00<00:00, 589424.26 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset.save_to_disk('../data/preprocessed/fingpt-ner-cls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk('../data/FinGPT/fingpt-ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = replace_dataset_col_with_transaltion(dataset, ner_translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 511/511 [00:00<00:00, 121467.23 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 98/98 [00:00<00:00, 36034.17 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset.save_to_disk('../data/preprocessed/fingpt-ner-cls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINRED-RE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk('../data/FinGPT/fingpt-finred-re')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = replace_dataset_col_with_transaltion(dataset, finred_re_translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 11400/11400 [00:00<00:00, 809080.94 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 2136/2136 [00:00<00:00, 457000.27 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset.save_to_disk('../data/preprocessed/fingpt-ner-cls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk('../data/FinGPT/fingpt-finred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = replace_dataset_col_with_transaltion(dataset, finred_translations)\n",
    "dataset = replace_dataset_col_with_transaltion(dataset, finred_general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 27558/27558 [00:00<00:00, 499728.19 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 5112/5112 [00:00<00:00, 451994.90 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset.save_to_disk('../data/preprocessed/fingpt-ner-cls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINRED-CLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk('../data/FinGPT/fingpt-finred-cls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = replace_dataset_col_with_transaltion(dataset, finred_cls_translations)\n",
    "dataset = replace_dataset_col_with_transaltion(dataset, finred_general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 48474/48474 [00:00<00:00, 1160299.80 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 8928/8928 [00:00<00:00, 1061626.35 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset.save_to_disk('../data/preprocessed/fingpt-ner-cls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HEADLINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk('../data/FinGPT/fingpt-headline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = replace_dataset_col_with_transaltion(dataset, headline_translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 82161/82161 [00:00<00:00, 2687443.64 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 20547/20547 [00:00<00:00, 2233461.99 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset.save_to_disk('../data/preprocessed/fingpt-headline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINANCE-ALPACA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = load_from_disk('../data/FinGPT/finance-alpaca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset_1['train'].to_pandas()\n",
    "\n",
    "df_without_input = df[df['input'].apply(lambda x : len(x) == 0)]\n",
    "df_with_input  = df[df['input'].apply(lambda x : len(x) != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 49184/49184 [00:00<00:00, 572833.05 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 19728/19728 [00:00<00:00, 1626889.55 examples/s]\n"
     ]
    }
   ],
   "source": [
    "save_new_dataset('../data/preprocessed/finance-alpaca-without-input', df_without_input)\n",
    "save_new_dataset('../data/preprocessed/finance-alpaca-with-input', df_with_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SENTIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "ds_train = load_from_disk('../data/FinGPT/fingpt-sentiment-train')\n",
    "\n",
    "# test\n",
    "ds_test = load_from_disk('../data/FinGPT/fingpt-sentiment-test')\n",
    "\n",
    "# combine them\n",
    "replaced_train_ds = replace_dataset_col_with_transaltion(ds_train, sentiment_translations)\n",
    "replaced_test_ds = replace_dataset_col_with_transaltion(ds_test, sentiment_translations)\n",
    "\n",
    "sentiment = DatasetDict()\n",
    "sentiment['train'] = replaced_train_ds['train']\n",
    "sentiment['test'] = replaced_test_ds['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 76772/76772 [00:00<00:00, 2262908.61 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 7922/7922 [00:00<00:00, 1322373.39 examples/s]\n"
     ]
    }
   ],
   "source": [
    "sentiment.save_to_disk('../data/preprocessed/fingpt-sentiment')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fingeitje",
   "language": "python",
   "name": "fingeitje"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
