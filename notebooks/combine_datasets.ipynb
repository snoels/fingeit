{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import fasttext\n",
    "from datasets import Dataset, DatasetDict, load_from_disk\n",
    "import pandas as pd\n",
    "\n",
    "import os \n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.data_processing.utils import is_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "model_path = hf_hub_download(\n",
    "    repo_id=\"facebook/fasttext-language-identification\", filename=\"model.bin\"\n",
    ")\n",
    "model = fasttext.load_model(model_path)\n",
    "\n",
    "all_data = {}\n",
    "\n",
    "def get_ds_and_check_deletion(name):\n",
    "    try:\n",
    "        old = load_from_disk(f'../data/FinGPT/{name}')\n",
    "    except:\n",
    "        old = load_from_disk(f'../data/preprocessed/{name}')\n",
    "    ds = load_from_disk(f'../data/reformatted/{name}')\n",
    "\n",
    "    for key in ds.keys():\n",
    "        perc_deleted = 1 - ds[key].num_rows/old[key].num_rows\n",
    "        print(key, 'deleted:', perc_deleted)\n",
    "\n",
    "    return ds\n",
    "\n",
    "def return_dutch_training_samples(df, cols, model):\n",
    "    is_dutch = df[cols].applymap(lambda x: is_language(x, model, 'nld')).all(axis = 1)\n",
    "    return df[is_dutch]\n",
    "\n",
    "def filter_non_dutch(ds, cols):\n",
    "\n",
    "    new_ds = DatasetDict()\n",
    "    \n",
    "    for key in ds.keys():\n",
    "        df = ds[key].to_pandas()\n",
    "        df = return_dutch_training_samples(df, cols, model)\n",
    "        new_ds[key] = Dataset.from_pandas(df, preserve_index=False)\n",
    "    \n",
    "    return new_ds\n",
    "\n",
    "def translate_sentence(sentence: str, translations: dict) -> str:\n",
    "    for eng, dutch in translations.items():\n",
    "        if eng in sentence:\n",
    "            sentence = sentence.replace(eng, dutch)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes\n",
    "# translations are being done again because a lot of the instructions were not correct so come back here if done\n",
    "# OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train deleted: 0.011983535664044198\n",
      "test deleted: 0.009341075485988393\n"
     ]
    }
   ],
   "source": [
    "name = 'fingpt-sentiment'\n",
    "\n",
    "sentiment = get_ds_and_check_deletion(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = {\n",
    "    'neutral' : 'neutraal',             \n",
    "    'mild positief' : 'matig positief',      \n",
    "    'mild negatief' : 'matig negatief', \n",
    "    'positive' : 'positief',   \n",
    "    'mildly positive' : 'matig positief', \n",
    "    'negative' : 'negatief',\n",
    "    'strong positive' : 'sterk positief',\n",
    "    'mildly negative' : 'matig negatief',\n",
    "    'mildly negatief' : 'matig negatief',\n",
    "    'strong positief' : 'sterk positief',\n",
    "    'mildly positief' : 'matig positief',\n",
    "}\n",
    "\n",
    "train = sentiment['train'].to_pandas()\n",
    "test = sentiment['test'].to_pandas()\n",
    "\n",
    "train['output'] = train.output.apply(lambda x : translate_sentence(x,translations))\n",
    "test['output'] = test.output.apply(lambda x : translate_sentence(x,translations))\n",
    "\n",
    "sentiment = DatasetDict({\n",
    "        'train': Dataset.from_pandas(train, preserve_index=False),\n",
    "        'test': Dataset.from_pandas(test, preserve_index=False)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_979523/1550996498.py:22: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  is_dutch = df[cols].applymap(lambda x: is_language(x, model, 'nld')).all(axis = 1)\n",
      "/tmp/ipykernel_979523/1550996498.py:22: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  is_dutch = df[cols].applymap(lambda x: is_language(x, model, 'nld')).all(axis = 1)\n"
     ]
    }
   ],
   "source": [
    "_sentiment = filter_non_dutch(sentiment, ['input','instruction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 75852/75852 [00:00<00:00, 2276539.16 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 7848/7848 [00:00<00:00, 1390189.11 examples/s]\n"
     ]
    }
   ],
   "source": [
    "sentiment.save_to_disk(f'../data/final_unfiltered/{name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 52781/52781 [00:00<00:00, 2240547.73 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 5788/5788 [00:00<00:00, 1246489.61 examples/s]\n"
     ]
    }
   ],
   "source": [
    "_sentiment.save_to_disk(f'../data/final_filtered/{name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes\n",
    "# the outputs need to be translated. general translations are not good\n",
    "# OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train deleted: 0.009325785615792115\n",
      "test deleted: 0.0013693270735524177\n"
     ]
    }
   ],
   "source": [
    "name = 'fingpt-finred'\n",
    "\n",
    "finred = get_ds_and_check_deletion(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2290/1550996498.py:22: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  is_dutch = df[cols].applymap(lambda x: is_language(x, model, 'nld')).all(axis = 1)\n",
      "/tmp/ipykernel_2290/1550996498.py:22: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  is_dutch = df[cols].applymap(lambda x: is_language(x, model, 'nld')).all(axis = 1)\n"
     ]
    }
   ],
   "source": [
    "_finred = filter_non_dutch(finred, ['instruction', 'input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 27301/27301 [00:00<00:00, 1161027.85 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 5105/5105 [00:00<00:00, 862583.97 examples/s]\n"
     ]
    }
   ],
   "source": [
    "finred.save_to_disk(f'../data/final_unfiltered/{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 9641/9641 [00:00<00:00, 957571.45 examples/s] \n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1790/1790 [00:00<00:00, 523410.78 examples/s]\n"
     ]
    }
   ],
   "source": [
    "_finred.save_to_disk(f'../data/final_filtered/{name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes\n",
    "# no filtering is done otherwise half of the samples is deleted\n",
    "# OK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train deleted: 0.1154598825831703\n",
      "test deleted: 0.22448979591836737\n"
     ]
    }
   ],
   "source": [
    "name = 'fingpt-ner'\n",
    "\n",
    "ner = get_ds_and_check_deletion(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_979523/1550996498.py:22: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  is_dutch = df[cols].applymap(lambda x: is_language(x, model, 'nld')).all(axis = 1)\n",
      "/tmp/ipykernel_979523/1550996498.py:22: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  is_dutch = df[cols].applymap(lambda x: is_language(x, model, 'nld')).all(axis = 1)\n"
     ]
    }
   ],
   "source": [
    "_ner = filter_non_dutch(ner, ['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 452/452 [00:00<00:00, 144741.59 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 76/76 [00:00<00:00, 31322.31 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ner.save_to_disk(f'../data/final_unfiltered/{name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 406/406 [00:00<00:00, 142560.69 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 68/68 [00:00<00:00, 30813.82 examples/s]\n"
     ]
    }
   ],
   "source": [
    "_ner.save_to_disk(f'../data/final_filtered/{name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ner-cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes\n",
    "# OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train deleted: 0.15956897187984354\n",
      "test deleted: 0.24271844660194175\n"
     ]
    }
   ],
   "source": [
    "name = 'fingpt-ner-cls'\n",
    "\n",
    "ner_cls = get_ds_and_check_deletion(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_979523/1550996498.py:22: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  is_dutch = df[cols].applymap(lambda x: is_language(x, model, 'nld')).all(axis = 1)\n",
      "/tmp/ipykernel_979523/1550996498.py:22: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  is_dutch = df[cols].applymap(lambda x: is_language(x, model, 'nld')).all(axis = 1)\n"
     ]
    }
   ],
   "source": [
    "_ner_cls = filter_non_dutch(ner_cls, ['input','instruction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 11387/11387 [00:00<00:00, 1303650.50 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 2652/2652 [00:00<00:00, 697254.07 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ner_cls.save_to_disk(f'../data/final_unfiltered/{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 9071/9071 [00:00<00:00, 1113709.14 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1959/1959 [00:00<00:00, 602084.09 examples/s]\n"
     ]
    }
   ],
   "source": [
    "_ner_cls.save_to_disk(f'../data/final_filtered/{name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes\n",
    "# translations done\n",
    "# OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train deleted: 0.0006450749138885437\n",
      "test deleted: 0.00048668905436322074\n"
     ]
    }
   ],
   "source": [
    "name = 'fingpt-headline'\n",
    "\n",
    "temp = get_ds_and_check_deletion(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections = {\n",
    "'Gaat de krantenkop over prijs? Kies alstublieft een antwoord uit {Ja/Nee}' : 'Gaat de krantenkop over de prijs? Kies alstublieft een antwoord uit {Ja/Nee}',    \n",
    "'Gaat de krantenkop over prijs staying constant': \"Gaat de krantenkop over de prijs die constant blijft\",\n",
    "'Gaat de krantenkop over prijs going down': \"Gaat de krantenkop over de prijs die omlaag gaat\",\n",
    "'Gaat de krantenkop over prijs going up': \"Gaat de krantenkop over de prijs die omhoog gaat\",\n",
    "'Gaat de krantenkop over prijs in het verleden': \"Gaat de krantenkop over de prijs in het verleden\",\n",
    "'Gaat de krantenkop over prijs in de toekomst' : \"Gaat de krantenkop over de prijs in de toekomst\",\n",
    "'Gaat de krantenkop over prijs in de future' : \"Gaat de krantenkop over de prijs in de toekomst\",\n",
    "'Gaat de krantenkop over prijs in the past' :  \"Gaat de krantenkop over de prijs in het verleden\",\n",
    "'Gaat de krantenkop over prijs constant blijven' : 'Gaat de krantenkop over de prijs die constant blijft',\n",
    "'Yes' : 'Ja',\n",
    "'No' : 'Nee'\n",
    "}\n",
    "\n",
    "train = temp['train'].to_pandas()\n",
    "test = temp['test'].to_pandas()\n",
    "\n",
    "train['instruction'] = train.instruction.apply(lambda x : translate_sentence(x,corrections))\n",
    "test['instruction'] = test.instruction.apply(lambda x : translate_sentence(x,corrections))\n",
    "\n",
    "train['output'] = train.output.apply(lambda x : translate_sentence(x,corrections))\n",
    "test['output'] = test.output.apply(lambda x : translate_sentence(x,corrections))\n",
    "\n",
    "\n",
    "headline = DatasetDict({\n",
    "        'train': Dataset.from_pandas(train, preserve_index=False),\n",
    "        'test': Dataset.from_pandas(test, preserve_index=False)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_996852/1550996498.py:22: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  is_dutch = df[cols].applymap(lambda x: is_language(x, model, 'nld')).all(axis = 1)\n",
      "/tmp/ipykernel_996852/1550996498.py:22: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  is_dutch = df[cols].applymap(lambda x: is_language(x, model, 'nld')).all(axis = 1)\n"
     ]
    }
   ],
   "source": [
    "_headline = filter_non_dutch(headline, ['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 82108/82108 [00:00<00:00, 2544316.15 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 20537/20537 [00:00<00:00, 2176971.83 examples/s]\n"
     ]
    }
   ],
   "source": [
    "headline.save_to_disk(f'../data/final_unfiltered/{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 36751/36751 [00:00<00:00, 1836719.73 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 9094/9094 [00:00<00:00, 1327082.34 examples/s]\n"
     ]
    }
   ],
   "source": [
    "_headline.save_to_disk(f'../data/final_filtered/{name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alpaca with input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes\n",
    "# OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train deleted: 0.04541768045417682\n"
     ]
    }
   ],
   "source": [
    "name = 'finance-alpaca-with-input'\n",
    "\n",
    "alapaca_input_temp = get_ds_and_check_deletion(name)\n",
    "\n",
    "alpaca_with_input = DatasetDict()\n",
    "\n",
    "for key in alapaca_input_temp.keys():\n",
    "    df = alapaca_input_temp[key].to_pandas()\n",
    "\n",
    "    df = df.drop(columns = ['text'])\n",
    "\n",
    "    alpaca_with_input[key] = Dataset.from_pandas(df, preserve_index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2290/1550996498.py:22: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  is_dutch = df[cols].applymap(lambda x: is_language(x, model, 'nld')).all(axis = 1)\n"
     ]
    }
   ],
   "source": [
    "_alpaca_with_input = filter_non_dutch(alpaca_with_input, ['input','instruction', 'output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 18832/18832 [00:00<00:00, 1515805.96 examples/s]\n"
     ]
    }
   ],
   "source": [
    "alpaca_with_input.save_to_disk(f'../data/final_unfiltered/{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 11118/11118 [00:00<00:00, 1395298.52 examples/s]\n"
     ]
    }
   ],
   "source": [
    "_alpaca_with_input.save_to_disk(f'../data/final_filtered/{name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alpaca without input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train deleted: 0.01854261548471048\n"
     ]
    }
   ],
   "source": [
    "name = 'finance-alpaca-without-input'\n",
    "\n",
    "alapaca_without_input_temp = get_ds_and_check_deletion(name)\n",
    "\n",
    "alpaca_without_input = DatasetDict()\n",
    "\n",
    "for key in alapaca_without_input_temp.keys():\n",
    "    df = alapaca_without_input_temp[key].to_pandas()\n",
    "\n",
    "    df = df.drop(columns = ['text'])\n",
    "\n",
    "    alpaca_without_input[key] = Dataset.from_pandas(df, preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2290/1550996498.py:22: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  is_dutch = df[cols].applymap(lambda x: is_language(x, model, 'nld')).all(axis = 1)\n"
     ]
    }
   ],
   "source": [
    "_alpaca_without_input = filter_non_dutch(alpaca_without_input, ['instruction', 'output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 48272/48272 [00:00<00:00, 1376243.53 examples/s]\n"
     ]
    }
   ],
   "source": [
    "alpaca_without_input.save_to_disk(f'../data/final_unfiltered/{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 32473/32473 [00:00<00:00, 1413642.56 examples/s]\n"
     ]
    }
   ],
   "source": [
    "_alpaca_without_input.save_to_disk(f'../data/final_filtered/{name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convfinqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train deleted: 0.029989193083573507\n",
      "test deleted: 0.024161073825503365\n"
     ]
    }
   ],
   "source": [
    "name = 'fingpt-convfinqa'\n",
    "\n",
    "convfinqa = get_ds_and_check_deletion(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2290/1550996498.py:22: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  is_dutch = df[cols].applymap(lambda x: is_language(x, model, 'nld')).all(axis = 1)\n",
      "/tmp/ipykernel_2290/1550996498.py:22: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  is_dutch = df[cols].applymap(lambda x: is_language(x, model, 'nld')).all(axis = 1)\n"
     ]
    }
   ],
   "source": [
    "_convfinqa = filter_non_dutch(convfinqa, ['input','instruction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 10771/10771 [00:00<00:00, 306200.68 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1454/1454 [00:00<00:00, 215731.65 examples/s]\n"
     ]
    }
   ],
   "source": [
    "convfinqa.save_to_disk(f'../data/final_unfiltered/{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 10713/10713 [00:00<00:00, 290523.84 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1453/1453 [00:00<00:00, 212323.58 examples/s]\n"
     ]
    }
   ],
   "source": [
    "_convfinqa.save_to_disk(f'../data/final_filtered/{name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fiqa-qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train deleted: 0.007247223845704309\n"
     ]
    }
   ],
   "source": [
    "name = 'fingpt-fiqa_qa'\n",
    "\n",
    "fiqa_qa_temp = get_ds_and_check_deletion(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiqa_qa = fiqa_qa_temp['train'].train_test_split(test_size=0.15, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2290/1550996498.py:22: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  is_dutch = df[cols].applymap(lambda x: is_language(x, model, 'nld')).all(axis = 1)\n",
      "/tmp/ipykernel_2290/1550996498.py:22: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  is_dutch = df[cols].applymap(lambda x: is_language(x, model, 'nld')).all(axis = 1)\n"
     ]
    }
   ],
   "source": [
    "_fiqa_qa = filter_non_dutch(fiqa_qa, ['input','instruction', 'output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 14438/14438 [00:00<00:00, 194020.10 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 2548/2548 [00:00<00:00, 176217.89 examples/s]\n"
     ]
    }
   ],
   "source": [
    "fiqa_qa.save_to_disk(f'../data/final_unfiltered/{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 12310/12310 [00:00<00:00, 795144.03 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 2187/2187 [00:00<00:00, 496989.91 examples/s]\n"
     ]
    }
   ],
   "source": [
    "_fiqa_qa.save_to_disk(f'../data/final_filtered/{name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine The Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/home/sandernoels/fingeit/data/final_filtered'\n",
    "\n",
    "frames = []\n",
    "\n",
    "for folder_name in os.listdir(path_to_data):\n",
    "    if os.path.isdir(os.path.join(path_to_data, folder_name)): \n",
    "        temp = load_from_disk(f'../data/final_filtered/{folder_name}')['train'].to_pandas()\n",
    "        temp['origin']  = folder_name\n",
    "        frames.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.concat(frames)\n",
    "final_filtered = temp[~temp.duplicated()].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 147788/147788 [00:00<00:00, 1270723.46 examples/s]\n"
     ]
    }
   ],
   "source": [
    "name = 'filtered_instruction_tuning_dataset'\n",
    "\n",
    "filtered_it_ds = DatasetDict()\n",
    "filtered_it_ds['train'] = Dataset.from_pandas(final_filtered, preserve_index=False)\n",
    "filtered_it_ds.save_to_disk(f'../data/final/{name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unfiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/home/sandernoels/fingeit/data/final_unfiltered'\n",
    "\n",
    "frames = []\n",
    "\n",
    "for folder_name in os.listdir(path_to_data):\n",
    "    if os.path.isdir(os.path.join(path_to_data, folder_name)): \n",
    "        temp = load_from_disk(f'../data/final_unfiltered/{folder_name}')['train'].to_pandas()\n",
    "        temp['origin']  = folder_name\n",
    "        frames.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.concat(frames)\n",
    "final_unfiltered = temp[~temp.duplicated()].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 246883/246883 [00:00<00:00, 1426268.56 examples/s]\n"
     ]
    }
   ],
   "source": [
    "name = 'unfiltered_instruction_tuning_dataset'\n",
    "\n",
    "unfiltered_it_ds = DatasetDict()\n",
    "unfiltered_it_ds['train'] = Dataset.from_pandas(final_unfiltered, preserve_index=False)\n",
    "unfiltered_it_ds.save_to_disk(f'../data/final/{name}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fingeitje",
   "language": "python",
   "name": "fingeitje"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
